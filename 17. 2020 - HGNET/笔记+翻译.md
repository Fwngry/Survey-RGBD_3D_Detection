open source：https://github.com/zaiweizhang/H3DNet

## 摘要

我们介绍了H3DNet，它将无色的三维点云作为输入，并输出一个面向对象的边界框（或BB）及其语义标签的集合。H3DNet的关键思想是预测一组混合的几何基元，即BB中心、BB面中心和BB边缘中心。我们展示了如何通过定义物体和几何基元之间的距离函数，将预测的几何基元转换成物体建议。这个距离函数可以对物体建议进行连续优化，其局部最小值可以提供高清晰度的物体建议。然后，H3DNet利用匹配和重构模块，将物体建议分类为检测到的物体，并对检测到的物体的几何参数进行微调。与使用单一类型的几何基元相比，混合几何基元集不仅为物体检测提供了更准确的信号，而且还为所产生的三维布局提供了一套超完整的约束。因此，H3DNet可以容忍预测的几何基元中的异常值。我们的模型在两个具有真实三维扫描的大型数据集上实现了最先进的三维检测结果，即ScanNet和SUN RGB-D。

## 引言

物体检测是视觉识别中的一个基本问题。在这项工作中，我们旨在从无色的三维点云中检测三维布局（即面向三维边界框（或BBs）和相关的语义标签）。由于不规则的输入和不同场景中不同数量的物体，这个问题从根本上说是具有挑战性的。选择合适的中间表征，将低层次的物体线索整合到检测到的物体中，是决定结果系统性能的关键。**虽然早期的工作[38, 39]将滑动窗口分类用于物体检测，但最近的工作[32, 4, 16, 29, 54, 28, 51, 35, 51, 27, 45]显示了设计端到端神经网络来生成、分类和重新定义物体建议的巨大前景。**

本文介绍了H3DNet，这是一个端到端的神经网络，利用一种新型的中间表征进行三维物体检测。具体来说，H3DNet首先预测一套混合的、超完整的几何基元（即BB中心、BB面中心和BB边缘中心），然后检测物体以满足这些基元及其相关特征。这种回归方法源于最近<u>基于关键点的姿势回归在6D物体姿势估计方面的成功[19, 25, 11, 21, 26, 36]</u>，在3D物体检测方面显示出两个有吸引力的优势。

首先，[每种类型的几何基元]都对应于[输入点云的不同区域]（例如，整个物体的点用于预测BB中心，平面边界表面的点用于预测相应的BB面中心）。结合不同的基元类型可以增加其**泛化行为的优势**。在新的实例上，它们比仅仅使用一种类型的基元提供了更多有用的约束和特征。其次，拥有一个超完整的基元约束集可以**容忍预测基元中的异常值**（例如，使用鲁棒函数），并减少个别预测错误的影响。H3DNet的设计充分体现了这两个优点。

具体来说，H3DNet由三个模块组成。

1. （预测）第一个模块计算密集的点状描述符，并使用它们来预测几何基元及其潜在特征。

2. （生成建议）第二个模块将这些几何基元转换为物体建议。

H3DNet的一个关键创新是确定一个参数化的距离函数，以评估物体BB和预测基元之间的距离。这个距离函数可以很容易地纳入不同的和不完整的几何基元。它的局部最小值自然对应于物体的建议。这种方法使我们能够不断优化对象BB，并从不精确的初始提议中生成高质量的对象提议。

3. （标签+微调）H3DNet的最后一个模块将每个物体建议分类为是否为检测到的物体，并为每个检测到的物体预测其几何参数的集合向量和语义标签，以便对检测结果进行微调。这<u>个模块的性能取决于输入。</u>由于每个物体的提议都与不同的几何基元相关，H3DNet聚集了与这些基元相关的潜在特征，这些特征可能包含互补的语义和几何信息，作为该模块的输入。

我们还引入了一种网络设计，可以处理不同数量的几何基元。

我们在两个流行的基准数据集ScanNet和SUN RGB-D上评估了H3DNet。在ScanNet上，H3DNet的mAP（0.25）达到了67.2%，与仅将三维点位置作为输入的最先进方法相比，有8.5%的相对改进。在SUN RGB-D上，H3DNet的mAP（0.25）达到了60.1%，与同一组最先进的方法相比，有2.4%的相对改善。

此外，在这两个数据集的困难类别上（即那些具有低mAP分数的类别），H3DNet的性能提升是显著的（例如，在窗户/门/淋浴帘上，分别从38.1/47.3/57.1到51.9/61.0/75.3/）。我们还对H3DNet进行了消融研究。实验结果证明了对混合和超完整的几何基元集进行回归以生成物体建议的重要性，以及聚合与匹配基元相关的特征以对检测到的物体进行分类和重定的重要性。综上所述，我们的工作的贡献是。

- 问题描述：将物体检测表述为**回归和聚合一个超完整的几何基元集**
- 不同场景和类型：预测适合不同物体类型和场景的多种类型的几何基元
- 只有点云：在**只有点云的SUN RGB-D和ScanNet上获得最先进的结果**

## 相关作品

### 三维物体检测

从方法论的角度来看，三维物体检测方法与二维物体检测方法之间存在着紧密的联系。大多数现有的工作都遵循对使用滑动窗口[38, 39]或更先进的技术[29, 54, 28, 51, 35, 51, 27, 45]生成的候选对象进行分类的方法。对象分类涉及基于模板的方法或深度神经网络。

二维方法和三维方法之间的关键区别在于特征表示。例如，

[23]利用一对语义背景的潜力来指导提案的对象性得分。

[32]使用定向梯度云（COG）进行物体检测。

3d-sis: 3d semantic instance segmentation of rgbd scans.[9]利用三维卷积神经网络的力量来识别三维物体的位置和关键点。由于3D领域的计算成本，许多方法利用2D-3D投影技术来整合2D物体检测和3D数据处理。例如，MV3D[4]和VoxelNet[54]在进入其余管道之前，以鸟瞰图表示三维输入数据。

[13, 16, 29]首先处理二维输入，以确定候选的三维物体建议。

点云已经成为三维深度学习的一个强有力的表示，特别是在提取突出的几何特征和空间位置方面（参见[30, 31]）。先前使用的基于点的神经网络包括分类[30, 31, 20, 44, 15, 48, 46, 47, 8, 10]，分割[31, 40, 2, 20, 44, 42, 15, 48, 46, 47, 8, 10, 7, 45]，正常估计[2]和三维重建[41, 6, 49]。

人们对点云的物体检测也越来越感兴趣[28, 51, 35, 51, 27, 45]。H3DNet与[28]最为相关，它利用深度神经网络来预测物体的边界盒。H3DNet的关键创新之处在于，它利用了一套超完整的几何基元和一个距离函数来整合它们进行物体检测。这

### 多任务三维理解

联合预测不同类型的几何基元与多任务学习有关[3, 12, 34, 33, 52, 24, 22, 18, 27, 55, 53]，其中将多个相关任务结合在一起可以提高特征学习的性能。在最近的工作HybridPose[36]中，Song等人表明，预测关键点、关键点之间的边缘和对称对应关系共同提升了每一类特征的预测精度。在本文中，我们表明预测BB中心、BB面中心和BB边缘中心共同有助于提高原始预测的泛化行为。超完整约束回归。H3DNet的主要思想是纳入一个超完整的约束集。与使用单一类型几何基元的[28]相比，这种方法实现了相当大的性能提升。在概念层面上，类似的策略已被用于物体跟踪[43]、零照细化分类[1]、6D物体姿势估计[36]和扫描之间的相对姿势估计[50]等任务。与这些工作相比，H3DNet的创新之处在于设计适合物体检测的混合约束条件，持续优化物体建议，聚集混合特征进行分类和细化物体建议，并对整个网络进行端到端的训练。

## 实验

![image-20210601115916553](https://oj84-1259326782.cos.ap-chengdu.myqcloud.com/uPic/2021/06_01_06_01_image-20210601115916553.png)

**VoteNet、GSPN、3D-SIS、DSS、F-PointNet、2D-Driven、Cloud of gradient**

✅ VoteNet [28] is a geometric-only detector that combines deep point set networks and a voting procedure. 

✅GSPN[51] uses a generative model for instance segmentation. 

✅Both 3D-SIS [9] and DSS [39] extract features from 2D images and 3D shapes to generate object proposals. 

✅F-PointNet [29] and 2D-Driven [17] ﬁrst propose 2D detection regions and project them to 3D frustum for 3D detection. 

✅Cloud of gradient(COG) [32] integrates sliding windows with a 3D HoG-like feature.

### 结果分析

如表2所示，在3D IoU阈值为0.25（mAP@0.25）的情况下，我们的方法在ScanNet V2上的平均mAP得分为67.2%，比表现最好的基线方法[28]好8.5%。此外，我们的方法比3D IoU阈值为0.5的基线方法[28]好14.6%（mAP@0.5）。

对于SUN RGB-D，在3D IoU阈值为0.25和0.5时，我们的方法在mAP方面分别提高了2.4%和6.1%。在这两个数据集上，我们的方法在mAP@0.5 下的性能提升大于在mAP@0.25 下的性能提升，这意味着我们的方法比基线方法能提供更准确的预测结果。

这样的改进归功于使用了一套超完整的几何基元及其相关的特征来生成和重新确定物体建议。我们也可以用类似的方式来理解SUN RGB-D比ScanNet的相对不突出的改进，**即前者的标签不如后者准确**，H3DNet的优势在SUN RGB-D上没有得到充分的利用。除了分类和重构模块，我们的方法与VoteNet有着相似的计算管道和复杂性。多个描述符塔和建议模块的计算可以并行进行，这不应该增加计算开销。在我们的实现中，我们的方法每次扫描最后一个模块需要0.058秒。从概念上讲，与[28]votenet相比，我们的方法需要多50%的时间，但操作起来的检测精度更高。

1. 对<u>薄型物体</u>的改进

目前表现最好的基线[28]的一个限制是预测三维场景中的薄物体，如门、窗和图片。相比之下，通过脸部和边缘基元，H3DNet能够为那些薄的物体提取更好的特征。**例如，窗户或图片的框架提供了密集的边缘特征，窗帘或浴帘的物理纹理提供了密集的面/表面特征。**H3DNet在薄型物体上有明显的性能提升，如门（13.7%）、窗（13.8%）、图片（10.8%）、窗帘（10.1%）和浴帘（18.2%）。

2. 对具有密集的几何基元的物体的改进

在表1中ScanNet的各个物体类别中，除了那些薄的物体外，我们的方法还导致了对橱柜（13.1%）、桌子（6.1%）、书架（10.3%）、冰箱（11.8%）、水槽（12.7%）和其他家具（16.4%）的显著性能提升。一种解释是，**这些物体类别的几何形状具有丰富的平面结构和/或明显的边缘结构，这对几何基元检测和物体重构有很大贡献。**

3. **基元匹配和重构的效果**

使用距离函数来重新确定对象的建议，并聚合匹配基元的特征，这对H3DNet来说至关重要。

在ScanNet上，仅仅对最初的提议进行分类，就使mAP 0.5的结果下降了14.6%。图4显示了定性的物体检测结果，这再次证明了优化和重定物体建议的重要性。

### 消融实验

1. 不同的几何基元所产生的影响

H3DNet结合：BB中心、BB边缘中心和BB面中心，将它们的泛化行为的强度加在一起。

<img src="https://oj84-1259326782.cos.ap-chengdu.myqcloud.com/uPic/2021/06_01_image-20210601123129175.png" alt="image-20210601123129175" style="zoom: 33%;" />

2. 建议微调 proposal refinement的影响

在物体建议重构过程中，物体中心、尺寸、航向角、语义和存在性都得到了优化。如表3所示，如果不对检测到的物体的任何几何参数进行微调，性能就会下降，这说明这个子模块的重要性。

<img src="https://oj84-1259326782.cos.ap-chengdu.myqcloud.com/uPic/2021/06_01_image-20210601122913909.png" alt="image-20210601122913909" style="zoom: 33%;" />

3. 不同截断阈值的影响

在不同的截断值δ下，mAP@0.25 和mAP@0.5 的结果保持稳定。这表明，我们的模型对不同的截断阈值δ是稳健的。

4. <u>多描述符计算塔 multiple descriptor computation towers</u> 的影响

H3DNet的一个超参数是描述符计算塔的数量。表4显示，添加更多的描述符计算塔会带来更好的结果，然而添加更多的描述符计算塔的性能增益很快就会下降。此外，H3DNet相对于VoteNet的性能增益来自于几何基元和物体提议匹配与重构的<u>混合集 hybrid set</u> of geometric primitives and object proposal matching and reﬁnement。例如，用H3DNet的四个描述符计算塔取代VoteNet的描述符计算塔，

在ScanNet和SUN RGB-D上分别只产生了少量的和没有的性能增益（见表4）

<img src="https://oj84-1259326782.cos.ap-chengdu.myqcloud.com/uPic/2021/06_01_image-20210601142309190.png" alt="image-20210601142309190" style="zoom: 33%;" />

## 结论和未来工作

在本文中，我们介绍了一种新型的三维物体检测方法，该方法将三维场景作为输入，并输出一组有标签和有方向的边界框。我们的方法的关键思想是预测一个混合和超完整的几何基元集，然后将检测到的物体与这些基元及其相关的特征相匹配。实验结果证明了这种方法在ScanNet和SUN RGB-D上的优势。在未来，我们希望将这种方法应用于<u>其他三维场景理解任务</u>，如实例分割和CAD模型重建。另一个未来的方向是整合<u>更多的几何基元</u>，如BB角，用于3D物体检测。

