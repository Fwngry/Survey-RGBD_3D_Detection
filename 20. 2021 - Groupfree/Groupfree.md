点云上的三维物体检测同时从三维点集中定位和识别三维物体。作为3D场景理解的一项基本技术，它在许多应用中发挥着重要作用，如自动驾驶、机器人操纵和增强现实。

与在二维规则图像上工作的二维物体检测不同，三维物体检测需要不规则和稀疏的点云作为输入，这使得它难以直接应用于二维物体检测技术的技术。最近的研究[27, 35, 26, 51]直接从不规则的输入点云中推断出物体位置并提取物体特征，用于物体检测。在这些方法中，需要一个点分组步骤，为每个候选物体分配一组点，然后从分配的点组中计算出物体特征。为此，人们研究了不同的分组策略。Frustum-PointNet[27]应用二维提案箱的Frustum包络进行点分组。Point R-CNN[35]将三维方框内的点分组为物体。VoteNet[26]将分组确定为投票给同一（或空间上接近的）中心点的点。尽管这些手工制作的分组方案有利于三维物体检测，但真实场景中物体的复杂性和多样性可能导致错误的点分配（如图1所示），并降低三维物体检测的性能。

在本文中，我们提出了一种简单而有效的技术，用于从点云中检测三维物体，而无需手工分组步骤。我们方法的关键思想是将点云中的所有点用于计算每个候选物体的特征，其中每个点的贡献由自动学习的注意力模块决定。基于这一思想，我们将Transformer应用于三维物体检测，它可以同时模拟物体与物体和物体与像素的关系，并提取物体特征，而无需手工分组。

为了进一步释放Transformer架构的力量，我们从两个方面对其进行了改进。首先，我们提出通过在不同阶段更新物体的空间编码来迭代重新定义物体的预测，而变形器的原始应用采用固定的空间编码。其次，我们在推理过程中使用所有阶段预测的检测结果的集合，而不是只使用最后阶段的结果作为最终结果。这两个修改有效地提高了三维物体检测的性能，而且计算开销很少。

我们用ScanNet V2[6]和SUN RGB-D[52]基准验证了我们的方法。结果表明，我们的方法是有效的，并且对初始物体候选者的质量是稳健的，即使是一个简单的最远点采样方法也能在ScanNet V2和SUN RGB-D基准上产生强大的结果。对于SUN RGB-D数据集，我们的方法和集合方案带来了显著的性能提升（+3.8 mAP@0.25）。在这两个基准上，我们提出的方法几乎没有什么花哨的东西，就取得了最先进的性能。

我们认为，我们的方法还主张通过使用注意力机制或变形金刚来进行点云建模，因为它自然地解决了三维点云所遇到的内在的不规则和稀疏分布问题，具有强大的潜力。

这与二维图像建模相反，在二维图像建模中，这类建模工具主要作为成熟的网格建模工具的挑战者或补充部分，如ConvNets变体[16, 32, 46]和RoI Align[2, 5]。