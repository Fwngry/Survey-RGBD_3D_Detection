> 在VOTENET基础上，融合图像中的2D投票和点云中的3D投票
>
> 1. 我们明确地从二维图像中提取几何和语义特征。我们利用相机参数将这些特征提升到三维。
> 2. 多塔训练方案

# IMVOTENET

## 摘要

由于点云深度学习的进展，三维物体检测已经取得了快速的进展。最近的一些工作甚至显示了仅有点云输入的最先进的性能（例如VOTE N ET）。**然而，点云数据有其固有的局限性。它们是稀疏的，缺乏颜色信息，并且经常受到传感器噪音的影响。另一方面，图像具有高分辨率和丰富的纹理。因此，它们可以补充点云所提供的三维几何图形。**然而，如何有效地利用图像信息来协助基于点云的检测仍然是一个开放的问题。

在这项工作中，我们在VOTENET的基础上，提出了一个名为IMVOTENET的3D检测架构，专门用于RGB-D场景。IMVOTENET是基于融合图像中的2D投票和点云中的3D投票。与之前的多模态检测工作相比，我们明确地从二维图像中提取几何和语义特征。我们利用相机参数将这些特征提升到三维。

**为了提高二维-三维特征融合的协同作用，我们还提出了一个多塔的训练方案。**我们在具有挑战性的SUN RGB-D数据集上验证了我们的模型，将最先进的结果提高了5.7 mAP。我们还提供了丰富的消融研究来分析每个设计选择的贡献。

## 简介

三维环境中物体的识别和定位是实现完整场景理解的重要第一步。即使是这样的低维场景表示也可以为自主导航和增强现实等应用服务。最近，随着点云数据深度网络的发展，一些作品[33, 56, 41]已经展示了以点云为唯一输入的最先进的三维检测结果。其中，Qi等人最近提出的VOTE N ET[33]工作，只采用3D几何输入，与之前利用所有RGB-D通道的工作相比，显示了室内物体识别的显著改善。这导致了一个有趣的研究问题。三维几何数据（点云）对于三维检测来说是否足够，或者是否有办法让RGB图像进一步提升当前的检测器？

通过研究点云数据和RGB图像数据的属性（例如见图1），我们认为答案是明确的：RGB图像在3D物体检测中具有价值。事实上，图像和点云提供了互补的信息。RGB图像比深度图像或LiDAR点云具有更高的分辨率，并包含点域中所没有的丰富纹理。此外，图像可以覆盖有源深度传感器的 "盲区"，这往往是由于反射面造成的。另一方面，图像在三维检测任务中是有限的，因为它们缺乏对物体深度和尺度的绝对测量，而这正是三维点云可以提供的。这些观察加强了我们的直觉，即图像可以帮助基于点云的三维检测。

## 实验

比较：在本节中，我们首先在具有挑战性的SUN RGB-D数据集上将我们的模型与之前的最先进的方法进行比较（第4.1节）。

可视化：接下来，我们提供了检测结果的可视化，显示了图像信息是如何帮助提高三维识别的（第4.2节）。

分析：然后，我们提出了一套广泛的分析性实验来验证我们的设计选择（第4.3节）。

其他实验：最后，我们在深度非常稀疏的情况下测试了我们的方法，并证明了它在这种情况下的稳健性（第4.4节）。

### 与最先进方法的比较

**基准数据集**

我们使用SUN RGB-D[42, 13, 51, 43]作为我们的评估基准，它是一个用于3D场景理解的单视角3 RGB-D数据集。它由∼10K RGB-D图像组成，其中5K用于训练。每张图像都有面向正交的三维边界盒的注释。总共有37个物体类别被注释。按照标准评估协议[45]，我们只对10个最常见的类别进行训练并报告结果。为了向点云骨干网络提供数据，我们使用提供的相机参数将深度图像转换为点云。RGB图像与深度通道对齐，并用于从场景三维点查询相应的图像区域。

**比较中的方法**

我们将I M VOTE N ET与之前同时使用几何学和RGB的方法进行比较。此外，由于以前的最先进的方法（VOTE N ET [33]）只使用几何信息，为了更好地欣赏我们提出的融合和梯度混合模块带来的改进，我们通过用图像的额外特征扩展基本的VOTE N ET，增加了两个强大的基线。

在以前为RGB-D设计的方法中，**2Ddriven[19]、PointFusion[52]和F-PointNet[34]都是级联系统，依靠2D检测器来提供3D的建议。**Deep Sliding Shapes[45]设计了一个Faster R-CNN[38]风格的3D CNN网络，从体素输入中生成3D建议，然后结合3D和2D RoI特征进行箱体回归和分类。COG[39]是一个基于滑动形状的检测器，使用从RGB-D数据中提取的类似3D HoG的特征。

至于VOTENET[33]的变化。第一种，("+RGB")，直接将RGB值作为一个三维向量附加到点云特征（种子点）上。对于第二种（"+region feature"），我们使用同样的预训练的Faster R-CNN（在我们的模型中）to obtain the region-leve<u>l one-hot class conﬁdence feature</u>，并将其串联到该二维箱体内部的种子点。这两种变化也可以被看作是我们方法的消减版本。

**结果**

<img src="https://oj84-1259326782.cos.ap-chengdu.myqcloud.com/uPic/2021/06_01_image-20210601172316168.png" alt="image-20210601172316168" style="zoom:50%;" />

与同样使用RGB数据的VOTENET的变化相比，我们的方法也显示出明显的优势。事**实上，我们发现，天真地将RGB值加入到点特征中会导致更差的性能，这可能是由于对RGB值的过分追求。**

将区域特征作为一个单次得分向量来添加有一定的帮助，但与我们更系统地利用图像投票的方法相比，仍然逊色。

**分析实验**

在本小节中，我们展示了对我们的设计选择的广泛消融研究，并讨论不同的模块如何影响模型的性能。对于所有的实验，我们像以前一样在SUN RGB-D上报告mAP@0.25。

**1. 对几何线索的分析**

为了验证从二维投票中提取的几何线索是否有帮助，我们消融了表2a中传递给三维种子点的几何特征（如公式6）。

我们看到，从第1行到第3行，不使用任何二维几何线索会导致2.2分的下降。另一方面，不使用射线角度导致1.2分的下降，**表明射线角度有助于为伪三维投票提供纠正线索。**

**2. 关于语义线索的分析**

表2b显示了来自二维图像的不同类型的区域特征如何影响三维检测性能。**我们看到，单枪匹马的类别得分向量（检测到的类别的概率得分，其他类别设为0）虽然简单，但导致了最佳结果。**直接使用来自Faster R-CNN网络的1024分值的RoI特征实际上得到了最差的数字，这可能是由于将这个高分值的特征与其他点的特征相融合的优化挑战。将1024分的特征减少到64分有帮助，但仍然不如简单的一击得分特征。

**3. 对纹理线索的分析**

表2c显示了不同的低层次图像特征（纹理特征）如何影响末端检测性能**。很明显，原始的RGB特征已经很有效了**，而更复杂的每像素CNN特征（来自Faster RCNN检测器的特征金字塔[23]）实际上可能由于过度罚款而受到损害。更多细节请见补充材料。

![image-20210601173202276](https://oj84-1259326782.cos.ap-chengdu.myqcloud.com/uPic/2021/06_01_image-20210601173202276.png)

**4. 梯度混合**

表3研究了tower weights如何影响梯度混合训练。

我们用几组有代表性的权重进行消融，包括单塔训练（第一行）、每个塔的主导权重（第二行至第四行）和我们的最佳设置。

值得注意的是，即使只有图像特征（第1行，第4列），即来自图像的伪投票和语义/纹理线索，**我们的表现已经超过了以前的几种方法（见表1），显示了我们融合和投票设计的力量。**

<img src="https://oj84-1259326782.cos.ap-chengdu.myqcloud.com/uPic/2021/06_01_image-20210601174304074.png" alt="image-20210601174304074" style="zoom:50%;" />

### 4.4. 用稀疏点云进行探测

虽然深度图像为一个场景提供了密集的点云（通常是10k到100k的点），但也有一些情况下只有稀疏的点可用。一个例子是，当点云是通过视觉里程学[29]或运动结构学（SfM）[17]计算出来的，其中三维点的位置是通过在多个视图中估计单眼相机的位置而三角化的。有了这样的稀疏数据，拥有一个仍能实现体面的检测性能的系统是很有价值的。

为了分析我们的模型在稀疏点云中的潜力，我们通过两种类型的点子采样来模拟点子少得多的扫描：

均匀随机子采样（以均匀分布去除现有的点）和基于ORB[40]关键点的子采样（对图像上的ORB关键点进行采样，只保留与这些2D关键点接近的3D点）。

在表4中，我们展示了不同分布和密度的点云输入的检测结果。<u>我们看到，在 "点云 "一栏中，随着点数量的减少，三维检测性能迅速下降。</u>

另一方面，我们看到包括图像线索在内的性能有明显的提高。当采样点来自ORB的关键点时，这种改善是最显著的，这些关键点的分布更加不均匀。

## 总结

在这项工作中，我们已经探索了<u>图像数据如何协助基于投票的三维pipeline</u>。我们建立的VOTE NET检测器依靠投票机制来有效地汇总点云中的几何信息。

（二维集成到三维）我们已经证明，我们的新网络IMVOTENET，可以利用现有的图像检测器来提供关于物体的几何和语义/纹理信息，其格式可以集成到三维投票管道中。具体而言，我们已经展示了如何利用相机参数和像素深度的知识，将二维几何信息提升到三维。

IMVOTENET利用梯度混合的多模式训练，极大地提高了三维物体检测性能，尤其是在点云稀疏或分布不利的情况下。