本文旨在为室内场景的模数化三维物体检测问题开发一个更快、更准确的解决方案。它是通过一个新型的神经网络实现的，该网络将一对RGB-D图像作为输入，并将定向的三维边界框作为输出。该网络名为3D-SSD，由两部分组成：**分层特征融合和多层预测**。

**（融合）分层特征融合结合了RGB-D图像的外观和几何特征，（预测）而多层预测则利用多尺度特征进行物体检测。**

因此，该网络能够以一种协同的方式利用2.5D表征来提高准确性和效率。物体大小的问题是通过在预测层的每个位置附加一组大小不同的三维锚箱来解决的。

在最后阶段，三维锚箱的类别分数分别以调整后的位置、大小和方向生成，从而导致使用非最大抑制的最终检测。

在训练阶段，借助于二维地面实况来识别阳性样本，以避免从原始数据中估算深度的噪音，从而指导一个更好的收敛模型。

在具有挑战性的SUN RGB-D数据集上进行的实验表明，我们的算法优于最先进的Deep Sliding Shape，mAP为10.2%，速度为88倍。此外，实验还表明，在NYUv2数据集上，即使输入图像尺寸较小，我们的方法也能达到相当的精度，并比最先进的方法快386倍。

![image-20210627003738316](https://oj84-1259326782.cos.ap-chengdu.myqcloud.com/uPic/2021/06_27_06_27_image-20210627003738316.png)

1. 融合：该网络将一对RGB-D图像作为输入，并将RGB和深度图像的外观和几何特征分层**融合**。
2. 在预测层的每个位置上附加一组手动设置尺寸的三维锚定框，其三维位置是由深度图像估计的。
3. 在不使用二维边界框建议的情况下，这些多尺度预测层被用来估计每个锚定框的类别分数，并对其位置、大小和方向偏移进行回归。

![image-20210627003914030](https://oj84-1259326782.cos.ap-chengdu.myqcloud.com/uPic/2021/06_27_06_27_image-20210627003914030.png)

## 一、引言

物体检测一直是一个受欢迎的研究领域，据报道，主要由于存在广泛可用的大规模数据集[6, 16, 24]和卷积神经网络（ConvNets）的发展，在快速的计算时间内具有很高的准确性。其目的是在图像平面上的物体周围产生二维边界盒，并确定其类别。然而，现实世界的应用

然而，现实世界的应用，如机器人处理物体、绘图和增强现实，需要3D信息，如姿势、尺寸和几何位置。

因此，室内场景中的模数化三维物体检测获得了越来越多的关注，特别是在便宜的RGB-D传感器（如Kinect和Xtion）推出后。我们的任务是在现实世界中产生一个围绕物体全部范围的三维边界框，即使是在部分观察下。目前对这个问题的解决方案大致可分为两类。

第一类，2.5D方法[28, 18, 10, 5]，将深度编码为彩色图像的一个额外通道，以充分利用成功的二维ConvNets，然后将二维建议与对应的三维方框相联系。

第二类，3D方法，将深度图像转换为点云，然后设计3D特征[26, 23]或开发3D ConvNets[27]，以更好地探索3D表示的几何信息。

尽管在这两个方向上都有令人信服和鼓舞人心的最新工作，但由于一些尚未解决的问题，进一步的工作是必须的。

(1) 从RGB-D图像生成的建议是计算密集型的。由于它在预测阶段是必不可少的，因此该网络不能适用于实时需求。

(2) 与二维两阶段检测器不同，大多数流行的三维提议生成器是不可分的，或独立于后来的识别网络，因此不能一起优化，失去了端到端的性能。

(3) 稀疏的三维数据的特征几乎没有特色。当把图像的像素投射到三维空间时，由于低分辨率和透视遮挡，生成的三维点云通常是嘈杂和稀疏的，这就限制了对具有突出形状特征的大型物体的检测。

**鉴于上述问题，我们准备用第三种方式建立一个端到端的RGB-D物体检测器，即预测密集的边界盒。所提出的网络被称为3D-SSD，它将一对RGB-D图像作为输入，并预测三维空间中物体的全部范围。**

如图1所示，在先前的特征提取网络之后，3D-SD由两部分组成：分层特征融合和多层预测。在分层特征融合部分，两个子网络分别用于从RGB和深度图像中学习外观和几何特征，然后在网络的多个阶段融合这些特征。

多层预测部分是流行的SSD[17]框架的三维泛化。为了解决尺度模糊的问题，我们在预测层的每个位置都附加了少量不同尺寸的三维锚箱。利用深度图像来确定这些锚箱的三维位置。

最后，小型卷积器被应用于这些多尺度特征层，以重新确定相对于每个锚箱的位置、大小和方向偏移，然后预测其物体类别。

我们在具有挑战性的SUN RGB-D和NYUv2数据集上评估我们的方法。实验表明，3D-SSD在准确性和效率方面都优于最先进的Deep Sliding Shape[27] [5]。我们的贡献可以概括为以下几点。

(1) 我们提出了一个新颖的**端到端**框架（3D-SSD），用于模态三维物体检测。它以一对RGBD图像为输入，以更快的速度准确预测三维空间中物体的位置、大小、方向和类别。

(2) 所提出的分层融合结构通过在网络的不同阶段串联特征层，全面地纳入了RGB和深度图像的外观和几何特征。这既考虑了物体的精细细节，也考虑了物体的高层次语义。

(3) 为了稳健起见，在训练阶段提出了一个二维边界盒地面真相辅助匹配策略来识别三维正样本。

(4) 实验结果证实了利用多尺度2.5D信息进行正交三维物体检测的有效性。

## 二、相关工作

自从RCNN的开创性工作[9]使用ConvNets预测图像平面上物体的可见部分周围的边界框以来，物体检测取得了快速进展。这项工作引起了广泛的关注，随后FastRCNN[8]、Faster-RCNN[22]、YOLO[20, 21]、SSD[17]、Mask-RCNN[12]、Focal Loss[15]等都逐步提高了准确性和速度。所有上述结果都是在二维的，早期有一些关于三维物体检测的工作开始出现[28, 29]。28]中给出的工作是为每个检测到的二维边界框产生多个假设的物体前景掩码，然后使用相应的点云来提取每个掩码的手工特征。DPM算法[7]适用于RGB-D图像，用于确定前景物体的三维位置。29]中给出的工作首先应用CPMC算法[3]来生成候选立方体。从RGBD图像中提取的特征和上下文关系被用来为这些立方体分配语义标签。随后，ConvNets的成功和3D传感器的到来开始推动了3D检测的新时代。在下面的段落中，我们将简要回顾现有的关于RGB-D图像的3D物体检测的工作，以及使用多层和多特征融合方法进行预测的主题。

RGB-D图像中的3D物体检测。滑动形状26]将深度图像转换为点云，然后在三维空间中滑动三维检测窗口。每个3D窗口的手工特征随后被输入每个物体类别的示范SVM。通过将CAD模型渲染成合成的深度图像来训练模范SVM。在三维空间中重复计算每个滑动窗口的三维特征，然后应用许多示范SVM，导致该方法的性能非常缓慢。与[26]类似。

[18]也在3D点云中采用了滑动窗口的方式，每个3D盒子的原始特征是通过对其在RGB和深度图像上的2D投影分别应用两个RCNN来计算的。然后，用CAD模型训练的深度玻尔兹曼机被用于原始特征，以利用RGB-D图像的跨模式特征。在最后阶段，模范SVMs被用于物体检测。同年，[10]采用RCNN，通过将深度图像编码为输入的3通道图像（局部表面法向量N x、N y和N z w.r.t重力估计），为二维图像中的每个实例分割估计一个粗略的姿势，然后用ICP对准CAD模型，以最佳方式匹配分割内的点云。

受Faster-RCNN的启发，Deep Sliding Shape[27]将从RGB-D图像中恢复的3D场景划分为3D体素网格，并设计了一个3D ConvNet（名为3D RPN）来提取3D区域建议，以更好地探索3D表示。然后，对于每个3D建议，另一个3D ConvNet（名为3D ORN）被用来学习物体类别和回归3D盒子。3D ConvNets的使用在准确性和效率方面都明显优于[26]。23]的工作为一个滑动的三维盒子设计了定向梯度云，从而极大地提高了性能[26]。

为了减少三维搜索空间，[13]利用Faster-RCNN检测RGB图像中的物体，然后利用每个二维边界框内的点云，通过多层感知器网络回归三维的位置和大小。在上述所有的工作中，[26]、[27]、[23]和[13]都做了曼哈顿世界的假设，滑动的三维盒子与估计的房间布局相一致。在[5]中给出的工作在RGB-D图像[11]中选择了耗时的外部多尺度组合分组（MCG）[1]来获得二维边界框建议。在Fast-RCNN的基础上，整合了RGB和深度图像上每个2D提案的特征，用于分类和3D盒子的回归。

在本文中，我们不对深度图像的点云进行重组，因为它通常是有噪声的，而且很费时间。我们的方法是一个单一的端到端框架，在二维图像中操作，不需要二维边界框建议。

使用多层的预测。最近的一些方法在ConvNet中使用多尺度特征层来改善二维物体检测（例如SSD[17]和FPN[14]）。虽然它们取得了令人鼓舞的性能，但现有的工作都没有利用ConvNets中的多层来检测RGB-D图像中的三维物体。在这项工作中，我们采用多尺度特征图来提高三维物体检测的性能。

**多特征融合。在大多数现有的工作中，在深度神经网络的后期阶段将RGB和深度图像的特征结合起来，用于3D物体检测。Wei等人[18]使用一个深度波尔兹曼机来融合两个独立的RCNN的特征。27]、[11]、[5]中的作品直接将来自RGB-D图像的特征连接起来，[4]设计了一个深度融合网络，在预测前将来自多个视图的区域性特征结合起来。我们的网络与以前的方法不同，因为我们在早期和中期阶段都分层融合了特征。**

## 三、3D-SSD Network

3D-SSD网络将一对RGB-D图像作为输入，并将RGB和深度图像的外观和几何特征分层融合。

然后，在预测层的每一个位置上附加一组人工设置的三维锚定框，其三维位置是由深度图像估计的。

在不使用二维边界框建议的情况下，这些多尺度预测层被用来估计每个锚定框的类别分数，并对其位置、大小和方向偏移进行回归。

![image-20210627003621518](https://oj84-1259326782.cos.ap-chengdu.myqcloud.com/uPic/2021/06_27_06_27_image-20210627003621518.png)