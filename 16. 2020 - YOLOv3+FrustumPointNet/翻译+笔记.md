## 摘要

本文旨在从点云中对室内和室外场景进行实时的高精度三维物体检测，只使用一个RGB-D相机。我们提出了一个新的网络系统，该系统结合了二维和三维物体检测算法，以达到更好的实时物体检测效果，并通过简化我们在真实机器人上的网络而拥有更快的速度。YOLOv3是最先进的基于2D图像的物体检测方法之一。

Frustum PointNets是一种使用frustum约束来预测物体的三维边界盒的实时方法。结合这两种方法可以有效地进行实时的2D-3D物体检测，无论是室内还是室外。

我们不仅提高了训练和评估精度，降低了KITTI物体检测基准的平均损失，而且在三个不同难度级别的所有类别的三维检测中取得了更好的平均精度（AP）。

此外，我们还在三种不同的硬件设备上实现了我们的机载实时2D和3D物体检测系统，只使用了一个RGB-D相机。

## 一、引言

现在，有很多优秀的基于深度卷积神经网络（CNN）的二维和三维物体检测方法，它们可以通过图形处理单元（GPU）加速来实现实时性，例如YOLO（Redmon和Farhadi，2018；Redmon等人。2016；Redmon等人，2016）、Faster R-CNN（Ren等人，2015）、Mask R-CNN（He等人，2017）和PointNets（Qi等人，2018；Qi等人，2017a；Qi等人，2017b）。尽管如此，对3D物体的准确和快速检测是一个挑战，在机器人技术中起着重要的作用，特别是对于自主驾驶。自主机器人被广泛应用于不同的研究领域，可以配备不同的传感器和强大的GPU。**RGB-D相机被广泛使用，与雷达或激光雷达传感器相比，它们更便宜、更轻便，同时提供丰富的场景信息，如3D彩色点云。具体来说，RGB图像为我们提供了有用的二维信息，可用于最先进的二维物体检测方法，而深度图对三维信息是有用的，如点云的几何位置，它提供了更多的物体几何信息。**

一些研究人员致力于研究结合二维和三维物体检测的方法，例如Frustum PointNets（Qi等人，2018）、MV3D（Chen等人，2017）、PointFusion（Xu等人，2018）和DenseFusion（Wang等人，2019）。与Frustum PointNets类似，我们的方法可以轻松有效地检测室外场景中的汽车和行人，这对自动驾驶和街道场景的理解非常有用。精确有效地检测室外场景中的汽车、行人和骑车人对自主驾驶和机器人避障很有帮助，而室内和室外场景中的人员检测对紧急救援和人机交互也很有帮助，并具有挑战性。

我们开发并分析了一个修改过的Frustum PointNet网络，它主要结合了二维和三维物体检测，以实现更好的点状物体检测精度，并在实时机器人应用上有更好的表现。我们还利用现有的KITTI物体检测基准（Geiger等人，2012）等基准，将我们提出的网络系统与Frustum PointNets算法进行比较。考虑到我们的系统具有良好的实时性能并可用于机器人，我们还在Robotnik Summit XL移动机器人以及Jetson TX2开发套件上实现了该系统。所有的测试实验都是在三种不同的硬件设备上进行和比较的。此外，在实际的室内和室外场景中，物体检测的性能也得到了提高。

我们在本文中的主要贡献是，我们提出了一个结合二维和三维物体检测方法的新策略，以达到更高的精度。另一个贡献是，我们在移动机器人中实现了二维和三维结合的物体检测，推理时间很快，而不是只在KITTI基准上进行训练和测试。最后但并非最不重要的是，我们的策略对室内和室外场景都很有效。