> 原文地址 [blog.csdn.net](https://blog.csdn.net/qq_40245826/article/details/101068660)
>
> 3D 物体检测和姿态估计
>
> 训练编码器 - 描述符匹配
>
> 训练阶段：（随机补丁）训练编码器-（合成补丁）创建codebook
>
> 测试阶段：检测-测试（采样-描述符-匹配-投票）

RGB-D Patches for 3D Object Detection and 6D Pose Estimation
-----------------------------------------------------------------------------------------

## 摘要

<img src="https://oj84-1259326782.cos.ap-chengdu.myqcloud.com/uPic/2021/05_25_5.png" alt="5" style="zoom:25%;" />

1. 重点工作：文章提出了一种 3D 目标检测方法，该方法使用局部采样的 RGB-D patch 的回归描述符进行 6D 投票。文章采用神经网络与基于局部投票相结合的方法，以卷积自动编码器（CAE）用于回归特征描述符，实现与包含局部 6D 姿态投票的密Codebook进行匹配，最后通过投票和过滤的方法得到最终精确结果。
2. 相关工作梳理与对比：相关工作中将基于模板和基于特征的方向进行了梳理：对比了基于**模板**的方法 [14,27,18] 与基于**描述符**的方法 [23,13,2] 以及基于**随机森林**的方法[5,30]，之后引出 CNN 法。
3. 我们对三个数据集进行评估，以表明我们的方法很好地概括了以前看不见的输入数据，提供了强大的检测结果，可以在目标数量可扩展的同时与现有技术竞争并超越现有技术。

## pipeline

4. 我们证明：**神经网络与基于局部投票的方法结合**可用于在杂波和遮挡下执行可靠的 3D 物体检测和姿态估计
5. 训练编码器、创建codebook：（随机补丁-训练编码器；合成补丁-创建codebook）我们使用来自 RGB-D 图像的随机补丁**从头开始训练卷积自动编码器**（CAE），目标是描述符回归。通过这个网络，**我们从目标视图中采样的合成补丁创建Codebook，其中每个Codebook条目都持有本地 6D 姿势投票**。
6. 检测：（采样-描述符-匹配-阈值）我们在常规网格上对输入图像中的补丁进行 **采样**，计算它们的**描述符**并将它们与具有近似 k-NN 搜索的Codebook进行**匹配**。匹配返回一些候选投票，只有当他们的匹配分数**超过阈值**时才会投票（参见图 2 中的示意图）。  
7. 测试：（匹配-投票-过滤）场景补丁描述符与合成模型视图补丁的数据库 **匹配** 并投射 6D 对象**投票**，随后将这些投票**过滤**到重新设定。

<img src="https://img-blog.csdnimg.cn/20190920172041518.PNG?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQwMjQ1ODI2,size_16,color_FFFFFF,t_70" style="zoom:33%;" />

## 方法

8. 本节中，我们首先描述如何对给定目标目标和场景的局部 RGB-D 片进行**采样**，同时确保作为神经网络输入的尺度不变性和适合性。(文中使用本地补丁的一个重要优点是它**避免了背景建模方面的问题**) 

<img src="https://img-blog.csdnimg.cn/20190920172110581.PNG?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQwMjQ1ODI2,size_16,color_FFFFFF,t_70" style="zoom:33%;" />

9. 其次，我们更详细地描述了所采用的**神经网络**。 

<img src="https://oj84-1259326782.cos.ap-chengdu.myqcloud.com/uPic/2021/05_25_watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQwMjQ1ODI2,size_16,color_FFFFFF,t_70.png" style="zoom: 33%;" />

10. 最后，我们提出了我们的**投票和过滤**方法，它使用经过训练的网络和来自合成补丁的回归描述符的Codebook，有效地检测真实场景中的目标。  

<img src="https://oj84-1259326782.cos.ap-chengdu.myqcloud.com/uPic/2021/05_25_watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQwMjQ1ODI2,size_16,color_FFFFFF,t_70-20210525103300338.png" style="zoom:33%;" />

##   结论

11. 我们证明了卷积自编码器能够从局部的 RGB-D 补丁中返回有意义的和有鉴别性的特征，甚至对于以前不可见的输入数据也是如此，这促进了我们的方法，并允许在不同级别的遮挡下进行健壮的多目标和多实例检测。
12. 此外，我们的投票转换具有内在的可伸缩（扩展）性，引入的过滤阶段允许抑制许多虚假投票。一个主要的观察结果是 CAEs 可以抽象出足够的数据来可靠地匹配真实数据和合成数据。