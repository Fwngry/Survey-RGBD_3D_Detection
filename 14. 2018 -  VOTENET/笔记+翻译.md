## 摘要

目前的三维物体检测方法受到二维检测器的严重影响。为了利用二维检测器的架构，它们通常将三维点云转换为常规网格（即体素网格或鸟瞰图像），或依靠二维图像的检测来提出三维方框。很少有作品试图直接检测点云中的物体。**在这项工作中，我们回归到第一原则，为点云数据构建一个三维检测pipeline，并尽可能地通用。**然而，由于数据的稀疏性--来自三维空间中的二维流形的样本--我们在从场景点直接预测边界盒参数时面临一个重大挑战：三维物体中心点可能远离任何表面点，因此很难在一个步骤中准确回归。**为了应对这一挑战，我们提出了VoteNet，一个基于深度点集网络和Hough投票的协同作用的端到端三维物体检测网络。**我们的模型在ScanNet和SUN RGB-D这两个大型真实三维扫描数据集上实现了最先进的三维检测，设计简单，模型尺寸紧凑，效率高。值得注意的是，**VoteNet通过使用纯粹的几何信息而不依赖彩色图像，超越了以前的方法。**

## 简介

三维物体检测的目标是对三维场景中的物体进行定位和识别。更具体地说，在这项工作中，我们的目标是估计定向的三维边界盒以及来自点云的物体语义类别。

与图像相比，三维点云提供了精确的几何形状和对光照变化的稳健性。另一方面，点云是不规则的。因此典型的CNN并不适合直接处理它们。

为了避免处理不规则的点云，目前的三维检测方法在各方面都严重依赖基于二维的检测器。

（3D卷积）**例如，[42，12]将Faster/Mask R-CNN[37，11]等二维检测框架扩展到三维。他们将不规则的点云体素化为规则的三维网格，并应用三维CNN检测器，这无法利用数据中的稀疏性，并且由于昂贵的三维卷积而导致高计算成本。**

Deep sliding shapes for amodal 3d object detection in rgb-d images.

3D-SIS: 3d semantic instance segmentation of rgb-d scans.

（牺牲几何细节）另外，[4，55]将点投射到常规的二维鸟瞰图上，然后应用二维检测器来定位物体。然而，这牺牲了几何细节，而这些细节在杂乱的室内环境中可能是至关重要的。

（2D驱动3D）最近，[20, 34]提出了一个级联的两步管道，首先检测前视图像中的物体，然后在从二维框中挤出的点云中定位物体，然而这严格依赖于二维检测器，如果没有在二维检测到物体，就会完全错过。

2d-driven 3d object detection in rgb-d images.

Frustum pointnets for 3d object detection from rgbd data. 

在这项工作中，我们引入了一个**以点云为重点**的三维检测框架，该框架直接处理原始数据，在结构和物体建议方面都不依赖于任何二维检测器。**我们的检测网络，VoteNet，是基于点云的三维深度学习模型的最新进展，并受到用于物体检测的广义Hough投票过程的启发[23]。**

我们利用PointNet++[36]，一个用于点云学习的分层深度网络，减轻了将点云转换为规则结构的需要。通过直接处理点云，我们不仅避免了量化过程带来的信息损失，而且还通过只对感知的点进行计算来利用点云的稀疏性。

虽然PointNet++在**物体分类和语义分割**方面取得了成功[36]，但很少有人研究如何用这种架构检测点云中的三维物体。**一个天真的解决方案是遵循二维检测器的普遍做法，进行密集的物体提议[29, 37]，即直接从感应到的点中提出三维边界框（有其学习的特征）。**

（深度传感器仅捕捉物体表面，中心处或许没有点）然而，点云固有的稀疏性使这种方法不可取。在图像中，物体中心附近往往存在一个像素，但在点云中往往不是这样。由于深度传感器只捕捉物体的表面，三维物体中心很可能在空旷的空间，离任何一个点都很远。因此，基于点的网络很难在物体中心附近聚集场景环境。简单地增加接受场并不能解决这个问题，因为当网络捕捉到更大的背景时，它也会导致更多的附近物体和杂波的加入。

**为此，我们建议赋予点云深度网络一个类似于经典Hough投票的投票机制。通过投票，我们基本上产生了靠近物体中心的新点，这些点可以被分组和聚合以产生盒子的建议。**

**相比传统的Hough投票多个独立的模块，难以联合优化，VoteNet是可以端到端优化的**。具体来说，在输入点云通过骨干网络后，我们对一组种子点进行采样，并根据它们的特征生成投票。**投票的目标是到达对象中心。**结果，在物体中心附近出现了投票集群，反过来又可以通过一个学习模块聚集起来，生成盒子建议。**其结果是一个强大的三维物体检测器，它是纯粹的几何学，可以直接应用于点云。**

我们在两个具有挑战性的三维物体检测数据集上评估我们的方法。SUN RGB-D[40]和ScanNet[5]。在这两个数据集上，仅使用几何图形的VoteNet明显优于同时使用RGB&GEO甚至是多视角RGB图像的sota。我们的研究表明，投票方案支持更有效的上下文聚合，并验证了当物体中心远离物体表面（如桌子、浴缸等）时，VoteNet提供了最大的改进。
总而言之，我们的工作的贡献是：

- 在深度学习的背景下，通过一个端到端的可微分架构重新表述Hough投票，我们称之为VoteNet。
- 在SUN RGB-D和ScanNet上实现了最先进的3D物体检测性能。
- 深入分析了投票对于点云中3D物体检测的重要性。

## 相关工作

三维物体检测。以前有许多方法被提出来检测物体的三维边界盒。例子包括。27]，其中一对语义上下文潜力有助于指导建议的对象性得分；基于模板的方法[26，32，28]；滑动形状[41]及其基于深度学习的后续方法[42]；定向梯度云（COG）[38]；和最近的3D-SIS[12]。

由于直接在三维中工作的复杂性，特别是在大场景中，许多方法都要借助某种类型的投影。例如，在MV3D[4]和VoxelNet[55]中，三维数据在进入其他管道之前首先被还原成鸟瞰图。Frustum PointNets[34]和[20]都证明了通过首先处理二维输入来减少搜索空间。同样，在[16]中，使用三维地图对分割假设进行了验证。最近，GSPN[54]和PointRCNN[39]使用点云上的深度网络来利用数据的稀疏性。

用于物体检测的Hough投票。Hough变换[13]最初于20世纪50年代末引入，将检测点样本中的简单模式的问题转化为检测参数空间中的峰值。广义Hough变换[2]进一步将这一技术扩展到图像斑块，作为复杂物体存在的指标。使用Hough投票的例子包括[24]的开创性工作，它引入了隐含形状模型，从三维点云中提取平面[3]，以及6维姿势估计[44]等等。在[30]中，投票被分配了表示其重要性的权重，这些权重是使用最大边际框架学习的。在[8，7]中介绍了用于物体检测的Hough森林。最近，[15]通过使用提取的深层特征来建立代码书，证明了基于投票的6D姿势估计的改进。同样，[31]学习了深度特征来建立编码簿，用于MRI和Ultrasiounds图像的分割。在[14]中，经典的Hough算法被用来提取汽车标志中的圆形图案，然后将其输入到深度分类网络。33]提出了用于图像中二维实例分割的半卷积算子，这也与Hough投票有关。

也有作品将Hough投票用于3D物体检测[50, 18, 47, 19]，它采用了与2D检测器类似的管道。

点云上的深度学习。最近，我们看到人们对设计适合点云的深度网络架构的兴趣大增[35, 36, 43, 1, 25, 9, 48, 45, 46, 22, 17, 53, 52, 49, 51]，这在三维物体分类、物体部分分割以及场景分割中表现出了显著的性能。在三维物体检测方面，VoxelNet[55]从体素中的点学习体素特征嵌入，而在[34]中，PointNets被用来定位从二维边界框挤出的壳点云中的物体。然而，很少有方法研究如何直接提出和检测原始点云表示中的三维物体。

## 实验

（SOTA）在这一节中，我们首先在两个大型的三维室内物体检测基准上，将我们基于Hough投票的检测器与之前最先进的方法进行比较（第5.1节）。

（消融）然后，我们提供了分析实验，以了解投票的重要性，不同的投票汇总方法的影响，并展示我们的方法在紧凑性和高效性方面的优势（第5.2节）。

（定性）最后我们展示了我们检测器的定性结果（第5.3节）。附录中提供了更多的分析和可视化信息。

### 最先进方法的比较

**数据集**

**SUN RGB-D**[40]是一个用于3D场景理解的单视角RGB-D数据集。它由5K个RGB-D训练图像组成，并为37个物体类别标注了正交方向的三维边界框。**为了给我们的网络提供数据，我们首先使用所提供的相机参数将深度图像转换成点云。我们遵循一个标准的评估协议，并报告了10个最常见类别的性能。**

ScanNetV2[5]是一个有丰富注释的室内场景**三维重建网格的数据集。**它包含了从数百个不同房间收集的120万个训练实例，并对18个物体类别进行了语义和实例分割的注释。与SUN RGB-D中的部分扫描相比，ScanNetV2中的场景更加完整，覆盖的区域更大，平均有更多的物体。我们从重建的网格中抽取顶点作为我们的输入点云。由于ScanNetV2不提供正交或定向的边界盒注释，我们的目的是预测轴对齐的边界盒，如[12]。

**比较中的方法**

✅我们与大量的现有技术方法进行比较。深度滑动图形（DSS）[42]和3D-SIS[12]都是基于3D CNN的检测器，它们在物体提议和分类中结合了几何和RGB线索，基于Faster R-CNN[37]管道。

与DSS相比，3D-SIS引入了一个更复杂的传感器融合方案（将RGB特征反投影到3D体素），因此能够使用多个RGB视图来提高性能。

✅2D-driven[20]和F-PointNet[34]是基于2D的3D检测器，依靠2D图像中的物体检测来减少3D检测的搜索空间。

✅Cloud of gradients[38]是一个基于滑动窗口的检测器，使用新设计的类似3D HoG的特征。MRCNN 2D-3D是一个天真基线，它直接将Mask-RCNN [11]实例分割结果投射到3D中，以获得一个边界框估计。

✅GSPN[54]是一种最新的实例分割方法，使用生成模型来提出物体实例，它也是基于PointNet++骨架的。

结果总结于表1和表2。

**VoteNet（ours）**优于所有以前的方法，在SUN RGB-D和ScanNet中分别增加了至少3.7和18.4 mAP。**值得注意的是，当我们只使用几何输入（点云）而他们同时使用几何和RGB图像时，我们取得了这样的改进。**

表1显示，在具有最多训练样本的 "椅子 "类别中，我们的方法比以前的技术水平提高了11个AP以上。

<img src="https://oj84-1259326782.cos.ap-chengdu.myqcloud.com/uPic/2021/05_30_05_30_image-20210530225318901.png" alt="image-20210530225318901" style="zoom:150%;" />

表2显示，当只使用几何输入时，我们的方法比基于3D CNN的方法3D-SIS要好得多，超过了33AP。

![image-20210530225521653](https://oj84-1259326782.cos.ap-chengdu.myqcloud.com/uPic/2021/05_30_05_30_image-20210530225521653.png)

附录中提供了ScanNet的每个类别的评估。重要的是，两个数据集都使用了同一套网络超参数。