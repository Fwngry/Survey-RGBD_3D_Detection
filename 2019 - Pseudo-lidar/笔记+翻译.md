> 1. 伪激光雷达的生成
> 2. 从深度图到伪激光雷达的转换非常快，应该可以通过例如模型蒸馏[1]或随时预测[14]来大幅加快检测管道的速度。
> 3. 伪激光雷达的优点是其信号比激光雷达密集得多，两种数据模式可以有互补的优势。
>
> 现实意义：https://www.sohu.com/a/338744319_465591
>
> 通过"图像Stereo-深度估计D-PseudoLiDAR- 3D point Detector"的处理方案代替“图像3D检测”的传统方案，迎合了当前智能驾驶中难以使用激光雷达的趋势，从原理上提出分析假设，并取得了很好的效果，同时展望了未来的改进策略

## 摘要

三维物体检测是自动驾驶的一项重要任务。如果三维输入数据来自精确但昂贵的LiDAR技术，那么最近的技术以高度准确的检测率而表现出色。到目前为止，基于更便宜的单眼或立体图像数据的方法导致准确率大幅下降--这一差距通常归因于基于图像的深度估计不佳。然

在本文中，我们认为，造成这种差异的主要原因不是数据的质量，而是其表示方法。考虑到卷积神经网络的内部运作，我们建议将**基于图像的深度图转换为伪激光雷达表示--基本上是模仿激光雷达信号。**有了这种表示，我们可以应用不同的现有基于LiDAR的检测算法。在流行的KITTI基准上，我们的方法在基于图像的性能方面取得了令人印象深刻的改进，将30米范围内物体的检测精度从以前的22%提高到了前所未有的74%。在提交报告时，我们的算法在KITTI三维物体检测排行榜上占据了**基于立体图像**的方法的最高位置。

![image-20210531170435390](https://oj84-1259326782.cos.ap-chengdu.myqcloud.com/uPic/2021/05_31_image-20210531170435390.png)

## 讨论和结论

(降低成本、备选方案)

简单的发现就能带来最大的差异。在本文中，我们已经表明，缩小基于图像和LiDAR的三维物体检测之间的差距的一个关键因素可能只是**三维信息的表示**。将这些结果看作是对系统缺陷的修正，而不是一种新的算法，可能是公平的，但是，这并没有削弱其重要性。<u>我们的发现与我们对卷积神经网络的理解是一致的，并通过经验结果得到证实。</u>事实上，我们从这一修正中获得的改进是前所未有的，对所有方法都有影响。有了这一飞跃，基于图像的自主车辆三维物体检测在不久的将来就会成为现实。这种前景的影响是巨大的。**目前，LiDAR硬件可以说是自主驾驶所需的最昂贵的额外组件。没有它，自主驾驶的额外硬件成本就变得相对较小。**此外，即使在有激光雷达设备的情况下，基于图像的物体检测也将是有益的。我们可以想象这样一个场景：**LiDAR数据被用来不断训练和微调基于图像的分类器。在我们的传感器发生故障的情况下，基于图像的分类器可以作为一个非常可靠的备份。**同样地，我们可以想象这样一种情况：高端汽车在出厂时就配备了激光雷达硬件。运送LiDAR硬件，并不断训练基于图像的分类器，这些分类器被用于较便宜的模型中。

## 方法

尽管基于图像的三维物体识别有许多优点，但在基于图像和LiDAR的方法的最先进的检测率之间仍有明显的差距（见第4.3节的表1）。我们很想把这种差距归结为LiDAR和相机技术之间明显的物理差异及其影响。例如，<u>基于立体</u>的三维深度估计的**误差**随着物体的**深度呈二次增长**，而对于<u>飞行时间（ToF）方法</u>，如LiDAR，这种关系大约是**线性的**。

尽管这些物理上的差异很可能造成了精度上的差距，但在本文中，我们声称很大一部分差异可以由数据表示来解释，而不是其质量或与数据收集相关的基本物理属性。

事实上，最近的立体深度估计算法可以产生令人惊讶的精确深度图[3]（见图1）。因此，我们 "缩小差距 "的方法是小心翼翼地消除两种数据模式之间的差异，并尽可能地调整两个识别管道。为此，我们提出了一个两步法，首先从立体（甚至是单眼）图像中估计密集的像素深度，然后将像素反投影到三维点云中。通过将这种表示方法视为伪激光雷达信号，我们就可以应用任何现有的基于激光雷达的三维物体检测算法。图2描述了我们的管道。

**深度估计**

我们的方法对不同的深度估计算法是不可知的。我们主要使用立体差异估计算法[3, 19]，尽管我们的方法可以很容易地使用单眼深度估计方法。

立体差异估计算法将一对左右图像IL和Ir作为输入，由一对具有水平偏移（即基线）b的相机拍摄，并输出与两幅输入图像中任何一幅相同大小的差异图Y。在不失一般性的情况下，我们假设深度估计算法将左边的图像I l作为参考，并在Y中记录每个像素与I r的水平差距。再加上左边相机的水平焦距f U，我们可以通过以下的变换得出深度图D。

<img src="https://oj84-1259326782.cos.ap-chengdu.myqcloud.com/uPic/2021/05_31_image-20210531170929470.png" alt="image-20210531170929470" style="zoom:50%;" />

**伪激光雷达的生成**

而不是像通常所做的那样，将深度D作为RGB图像的多个附加通道[30]，我们可以得出每个像素（u,v）的三维位置（x,y,z），在左边相机的坐标系中，如下所示

<img src="https://oj84-1259326782.cos.ap-chengdu.myqcloud.com/uPic/2021/05_31_image-20210531171215445.png" alt="image-20210531171215445" style="zoom:50%;" />

其中（cU , cV ）是对应于相机中心的像素位置，fV是垂直焦距。

通过将所有的像素反投影到三维坐标，我们得到一个三维点云

<img src="https://oj84-1259326782.cos.ap-chengdu.myqcloud.com/uPic/2021/05_31_image-20210531171348359.png" alt="image-20210531171348359" style="zoom:50%;" />

其中N是像素数。这样的点云可以在给定的参考视点和观察方向下被转换为任何环形坐标框架。我们把产生的点云称为<u>伪激光雷达信号</u>

**LiDAR与伪LiDAR**

为了与现有的LiDAR探测管道最大限度地兼容，我们对伪LiDAR数据进行了一些额外的后处理步骤。由于真实的LiDAR信号只存在于一定的高度范围内，我们不考虑超出该范围的伪LiDAR点。例如，在KITTI基准测试中，按照[33]，我们删除了高于虚假LiDAR源（位于自主车辆顶部）1米的所有点。由于大多数感兴趣的物体（如汽车和行人）都不超过这个高度范围，所以信息损失不大。除了深度之外，LiDAR还返回任何测量像素的反射率（在[0,1]范围内）。由于我们没有这样的信息，我们只是将每个伪激光雷达点的反射率设置为1.0。

图1描述了KITTI数据集[11, 12]中同一场景的地面实测LiDAR和伪LiDAR点。深度估计是通过金字塔立体匹配网络（PSMNet）[3]获得的。**令人惊讶的是，伪LiDAR点（蓝色）与真正的LiDAR点（黄色）对准得非常好，这与人们普遍认为基于图像的低精度深度是导致劣质3D物体检测的主要原因相反。我们注意到，LiDAR可以为一个场景捕获超过100,000个点，这与像素数是同一个数量级。然而，LiDAR的点是沿着几个（通常是64或128）水平光束分布的，只是稀疏地占据了三维空间。**

**三维物体检测**

有了估计的伪激光雷达点，我们可以将任何现有的基于激光雷达的三维物体检测器用于自主驾驶。在这项工作中，我们考虑那些基于多模态信息（即单眼图像+LiDAR），因为将原始视觉信息与伪LiDAR数据结合在一起是很自然的。具体来说，我们在AVOD[16]和frustum PointNet[23]上进行了实验，这两个算法在KITTI基准上的代码是开源的，排名靠前。一般来说，我们区分了两种不同的设置。

a) 在第一种设置中，我们将伪激光雷达信息视为三维点云。在这里，我们使用F-pointnet[23]，将二维物体检测[18]投射到三维frustum中，然后应用pointnet[24]来提取每个三维地壳的点集特征。

b) 在第二个设置中，我们从鸟瞰图（BEV）中查看伪激光雷达信息。特别是，三维信息被转换为自上而下的二维图像：宽度和深度成为空间尺寸，高度被记录在通道中。AVOD将视觉特征和BEV LiDAR特征连接到三维方框建议，然后将两者融合在一起，进行方框分类和回归。

**数据表示很重要**

虽然伪激光雷达传达的信息与深度图相同，<u>**但我们声称它更适合于基于深度卷积网络的三维物体检测管道。**</u>

要看到这一点，请考虑卷积网络的核心模块：2D卷积。在图像或深度图上操作的卷积网络在图像/深度图上执行一系列的二维卷积。尽管卷积的矩阵可以被学习，但核心假设是双重的。(a)图像中的局部邻域有意义，网络应该关注局部斑块；(b)所有邻域都能以相同的方式进行操作。这些都是不完美的假设。首先，二维图像上的局部斑块只有在完全包含在一个物体中时才是物理上的一致。如果它们跨越了物体的边界，那么两个像素在深度图中可能是相邻的，但在三维空间中却可能非常遥远。第二，出现在多个深度的物体在深度图中投射到不同的尺度。一个同样大小的斑块可能只捕捉到附近汽车的侧视镜，或远处汽车的整个车身。现有的二维物体检测方法在这种假设的分解上很吃力，不得不设计新的技术，如特征金字塔[18]来应对这一挑战。

相比之下，**点云上的三维卷积或鸟瞰图片中的二维卷积是对物理上接近的像素进行操作的**（尽管后者确实将不同高度的像素拉在一起，但世界的物理学意味着在特定空间位置上不同高度的像素通常属于同一个物体）。**此外，远处的物体和近处的物体的处理方式也完全相同。因此，这些操作在本质上更具有物理意义，因此应该导致更好的学习和更准确的模型。**

为了进一步说明这一点，在图3中我们进行了一个简单的实验。

在左栏中，我们显示了原始深度图和图像场景的伪激光雷达表示。场景中的四辆汽车以颜色突出显示。

我们对深度图（右上角）进行了一次11×11的卷积，该卷积与5层3×3的卷积的接受场相匹配。然后，我们将得到的（模糊的）深度图转换成伪LiDAR表示（右下）。从图中可以明显看出，这种新的伪激光雷达表示法受到了模糊的影响。<u>汽车被拉长了，远远超出了它们的实际物理比例，使其基本上无法准确定位。为了实现更好的可视化，我们添加了包含绿色和青色汽车的所有点的矩形。在卷积之后，这两个界线盒都捕捉到了高度错误的区域。</u>

**当然，二维卷积网络将学会使用比框式滤波器更智能的滤波器，但这个例子显示了卷积网络可能进行的一些操作是如何接近于荒谬的**。

<img src="https://oj84-1259326782.cos.ap-chengdu.myqcloud.com/uPic/2021/05_31_image-20210531173404877.png" alt="image-20210531173404877" style="zoom:50%;" />

## 未来的工作

在未来的工作中，我们的成果有多个直接的方向可以改进。

首先，更高分辨率的立体图像可能会大大改善远处物体的准确性。我们的结果是用40万像素获得的，与最先进的相机技术相差甚远。

第二，在本文中，我们没有关注实时图像处理，对一幅图像中所有物体的分类需要1秒的时间。最近对实时多分辨率深度估计的改进[28]表明，**加快深度估计**的一个有效方法是首先在低分辨率下计算深度图，然后结合高分辨率来重新确定先前的结果。

**从深度图到伪激光雷达的转换非常快，应该可以通过例如模型蒸馏[1]或随时预测[14]来大幅加快检测管道的速度。**最后，未来的工作可能会通过LiDAR和伪LiDAR的传感器融合来提高3D物体检测的先进性。**伪激光雷达的优点是其信号比激光雷达密集得多，两种数据模式可以有互补的优势。**我们希望我们的发现将引起基于图像的三维物体识别的复兴，我们的进展将激励计算机视觉界在不久的将来完全消除**图像/激光雷达的差距。**