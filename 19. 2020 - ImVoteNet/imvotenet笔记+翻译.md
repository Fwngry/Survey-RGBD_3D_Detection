> 在VOTENET基础上，融合图像中的2D投票和点云中的3D投票
>
> 二维检测器-YOLO
>
> 1. 相对于只使用point cloud的votenet，imvotenet从二维图像中提取几何和语义特征，利用相机参数将这些特征提升到三维（Geo cues）
> 2. 此外还从RGB中提取到了（semantic cues、texture cues）
> 3. 多塔训练方案
> 4. 在点云稀疏的情景下，2D图像反过来辅助提升了性能

> 融合2d的好处：
>
> 二维投票将三维物体中心的搜索空间减少到一条射线，而图像中的颜色纹理提供了一个强大的语义先验。由于种子特征同时具有二维和三维信息，它们对于恢复严重截断的物体或点少的物体来说，直观上更有参考价值，而且在区分几何上相似的物体方面也更有说服力。

> 我们设计的一个动机是利用二维图像中的几何和语义/纹理线索（图1）。几何线索来自于图像中准确的二维边界框，如二维检测器的输出。我们并不完全依靠二维检测来提出物体，而是将提议过程推迟到三维。给定一个二维盒子，我们在图像空间上生成二维投票，每张投票都从物体像素连接到二维正交盒子中心。为了将二维投票传递到三维，我们通过应用基于相机本征和像素深度的几何变换来提升它们，从而产生 "伪 "三维投票。这些伪三维选票成为附加在三维种子点上的额外特征，用于物体建议。除了来自二维投票的几何线索外，每个像素还将语义和纹理线索传递给三维点，作为每个区域提取的特征或每个像素提取的特征。
>
> 三维点特征连接起来、投票汇总以产生最终的三维物体检测

# IMVOTENET

## 摘要

由于点云深度学习的进展，三维物体检测已经取得了快速的进展。最近的一些工作甚至显示了仅有点云输入的最先进的性能（例如VOTENET）。**然而，点云数据有其固有的局限性。它们是稀疏的，缺乏颜色信息，并且经常受到传感器噪音的影响。另一方面，图像具有高分辨率和丰富的纹理。因此，它们可以补充点云所提供的三维几何图形。**然而，如何有效地利用图像信息来协助基于点云的检测仍然是一个开放的问题。

在这项工作中，我们在VOTENET的基础上，提出了一个名为IMVOTENET的3D检测架构，专门用于RGB-D场景。IMVOTENET是基于融合图像中的2D投票和点云中的3D投票。与之前的多模态检测工作相比，我们明确地从二维图像中提取几何和语义特征。我们利用相机参数将这些特征提升到三维。

**为了提高二维-三维特征融合的协同作用，我们还提出了一个多塔的训练方案。**我们在具有挑战性的SUN RGB-D数据集上验证了我们的模型，将最先进的结果提高了5.7 mAP。我们还提供了丰富的消融研究来分析每个设计选择的贡献。

![image-20210615114412936](https://oj84-1259326782.cos.ap-chengdu.myqcloud.com/uPic/2021/06_15_image-20210615114412936.png)

## 简介

三维环境中物体的识别和定位是实现完整场景理解的重要第一步。即使是这样的低维场景表示也可以为自主导航和增强现实等应用服务。最近，随着点云数据深度网络的发展，一些作品[33, 56, 41]已经展示了以点云为唯一输入的最先进的三维检测结果。其中，Qi等人最近提出的VOTE NET[33]工作，只采用3D几何输入，与之前利用所有RGB-D通道的工作相比，显示了室内物体识别的显著改善。这导致了一个有趣的研究问题。

<u>三维几何数据（点云）对于三维检测来说是否足够，或者是否有办法让RGB图像进一步提升当前的检测器？</u>通过研究点云数据和RGB图像数据的属性（例如见图1），我们认为答案是明确的：RGB图像在3D物体检测中具有价值。事实上，图像和点云提供了互补的信息。

（1）RGB图像比深度图像或LiDAR点云具有更高的分辨率，并包含点域中所没有的丰富纹理。此外，图像可以覆盖有源深度传感器的 "盲区"，这往往是由于反射面造成的。

（2）另一方面，图像在三维检测任务中是有限的，因为它们缺乏对物体深度和尺度的绝对测量，而这正是三维点云可以提供的。这些观察加强了我们的直觉，即图像可以帮助基于点云的三维检测。

然而，如何在三维检测管道中有效利用二维图像仍然是一个开放的问题。一个简单的方法是直接将原始RGB值添加到点云中--因为点与像素的对应关系可以通过投影建立。但由于三维点要稀疏得多，这样做我们会失去图像领域的密集模式。有鉴于此，最近有人提出了更先进的融合二维和三维数据的方法。

（1）Frustum pointnet、2D driven 3D、pointfusion？：2D proposal

有一项工作[34, 52, 19]使用成熟的二维检测器，以地壳的形式提供初始建议。这限制了用于估计三维边界盒的三维搜索空间。然而，由于其级联设计，它在初始检测中没有利用三维点云。特别是，如果一个物体在二维中被遗漏，它在三维中也会被遗漏。

（2）DDS、joint？、densefusion？、3D-sis

另一项工作[45, 18, 48, 11]采取了一种更注重三维的方式，将二维图像的<u>中间ConvNet特征串联到三维体素或点上，以丰富三维特征，然后再用于物体提议和箱体回归。</u>这类系统的缺点是它们没有直接使用二维图像进行定位，而二维图像可以为检测三维物体提供有用的指导。

在我们的工作中，我们在成功的VOTENET架构[33]的基础上，设计了一个用于3D物体检测的2D-3D联合投票方案，名为imvotenet。它利用了更成熟的二维检测器[38]，但同时仍然保留了从完整的点云中提出物体的能力--结合了这两个工作路线的优点，同时避免了各自的缺点。

我们设计的一个动机是利用二维图像中的几何和语义/纹理线索（图1）。几何线索来自于图像中准确的二维边界框，如二维检测器的输出。我们并不完全依靠二维检测来提出物体[34]，而是将提议过程推迟到三维。给定一个二维盒子，我们在图像空间上生成二维投票，每张投票都从物体像素连接到二维正交盒子中心。为了将二维投票传递到三维，我们通过应用基于相机本征和像素深度的几何变换来提升它们，从而产生 "伪 "三维投票。这些伪三维选票成为附加在三维种子点上的额外特征，用于物体建议。除了来自二维投票的几何线索外，每个像素还将语义和纹理线索传递给三维点，作为每个区域提取的特征或每个像素提取的特征。

在将所有的特征从图像提升到三维后，我们将它们与来自点云主干网络的三维点特征连接起来pointnet、pointnet++：[35, 36]。融合了二维和三维特征的点产生三维Hough投票[12]--不受二维框的限制--指向物体中心，并将投票汇总以产生最终的三维物体检测。

由于种子特征同时具有二维和三维信息，它们对于恢复严重截断的物体或点少的物体来说，直观上更有参考价值，而且在区分几何上相似的物体方面也更有说服力。



（多塔网络结构）在融合二维和三维信息源时，必须仔细平衡来自两种模式的信息，以避免其中一种被另一种所支配。为此，我们进一步引入了一个带有梯度混合的多塔网络结构[49]，以确保我们的网络能够最好地利用二维和三维特征。在测试过程中，只使用对二维和三维联合特征进行操作的主塔，将对效率的牺牲降到最低。

我们在具有挑战性的SUN RGB-D数据集[43]上评估了imvotenet。我们的模型达到了最先进的结果，同时比只有三维几何的votenet有明显的改进（+5.7 mAP），验证了图像投票和二维特征的有用性。

我们还提供了广泛的消融研究，以证明每个单独组件的重要性。

最后，我们还探讨了使用颜色来补偿深度点的稀疏性的可能性，特别是对于质量较差的深度传感器或从移动的单眼相机（SLAM）估计深度的情况，显示了我们的方法在更广泛的使用情况下的潜力。

总而言之，我们工作的贡献是。

1. 一种几何原理上的方法，将2D物体检测线索融合到基于点云的3D检测管道中。

2. 设计的深度网络I M VOTE N ET在SUN RGB-D上实现了最先进的3D物体检测性能。

3. 广泛的分析和可视化，以了解系统的各种设计选择。

## 实验



### 与最先进方法的比较

**基准数据集**

我们使用SUN RGB-D[42, 13, 51, 43]作为我们的评估基准，它是一个用于3D场景理解的单视角3 RGB-D数据集。它由∼10K RGB-D图像组成，其中5K用于训练。每张图像都有面向正交的三维边界盒的注释。总共有37个物体类别被注释。按照标准评估协议[45]，我们只对10个最常见的类别进行训练并报告结果。为了向点云骨干网络提供数据，我们使用提供的相机参数将深度图像转换为点云。RGB图像与深度通道对齐，并用于从场景三维点查询相应的图像区域。

**比较中的方法**

我们将imvotenet与之前同时使用几何学和RGB的方法进行比较。此外，由于以前的最先进的方法（VOTE N ET [33]）只使用几何信息，为了更好地欣赏我们提出的融合和梯度混合模块带来的改进，我们通过用图像的额外特征扩展基本的votenet，增加了两个强大的基线。

在以前为RGB-D设计的方法中，**2Ddriven[19]、PointFusion[52]和F-PointNet[34]都是级联系统，依靠2D检测器来提供3D的建议。**Deep Sliding Shapes[45]设计了一个Faster R-CNN[38]风格的3D CNN网络，从体素输入中生成3D建议，然后结合3D和2D RoI特征进行箱体回归和分类。COG[39]是一个基于滑动形状的检测器，使用从RGB-D数据中提取的类似3D HoG的特征。

至于VOTENET[33]的变化。第一种，("+RGB")，直接将RGB值作为一个三维向量附加到点云特征（种子点）上。对于第二种（"+region feature"），我们使用同样的预训练的Faster R-CNN（在我们的模型中）to obtain the region-leve<u>l one-hot class conﬁdence feature</u>，并将其串联到该二维箱体内部的种子点。这两种变化也可以被看作是我们方法的消减版本。

**结果**

<img src="https://oj84-1259326782.cos.ap-chengdu.myqcloud.com/uPic/2021/06_01_image-20210601172316168.png" alt="image-20210601172316168" style="zoom:50%;" />

与同样使用RGB数据的VOTENET的变化相比，我们的方法也显示出明显的优势。事**实上，我们发现，天真地将RGB值加入到点特征中会导致更差的性能，这可能是由于对RGB值的过分追求。**

**分析实验**

在本小节中，我们展示了对我们的设计选择的广泛消融研究，并讨论不同的模块如何影响模型的性能。对于所有的实验，我们像以前一样在SUN RGB-D上报告mAP@0.25。

**1. 对几何线索的分析**

为了验证从二维投票中提取的几何线索是否有帮助，我们消融了表2a中传递给三维种子点的几何特征（如公式6）。

我们看到，从第1行到第3行，不使用任何二维几何线索会导致2.2分的下降。另一方面，不使用射线角度导致1.2分的下降，**表明射线角度有助于为伪三维投票提供纠正线索。**

**2. 关于语义线索的分析**

表2b显示了来自二维图像的不同类型的区域特征如何影响三维检测性能。**我们看到，单枪匹马的类别得分向量（检测到的类别的概率得分，其他类别设为0）虽然简单，但导致了最佳结果。**直接使用来自Faster R-CNN网络的1024分值的RoI特征实际上得到了最差的数字，这可能是由于将这个高分值的特征与其他点的特征相融合的优化挑战。将1024分的特征减少到64分有帮助，但仍然不如简单的一击得分特征。

**3. 对纹理线索的分析**

表2c显示了不同的低层次图像特征（纹理特征）如何影响末端检测性能**。很明显，原始的RGB特征已经很有效了**，而更复杂的每像素CNN特征（来自Faster RCNN检测器的特征金字塔[23]）实际上可能由于过度罚款而受到损害。更多细节请见补充材料。

![image-20210601173202276](https://oj84-1259326782.cos.ap-chengdu.myqcloud.com/uPic/2021/06_01_image-20210601173202276.png)

### 4.4. 用稀疏点云进行探测

（不得不面对稀疏电云场景）虽然深度图像为一个场景提供了密集的点云（通常是10k到100k的点），但也有一些情况下只有稀疏的点可用。一个例子是，当点云是通过视觉里程学[29]或运动结构学（SfM）[17]计算出来的，其中三维点的位置是通过在多个视图中估计单眼相机的位置而三角化的。有了这样的稀疏数据，拥有一个仍能实现体面的检测性能的系统是很有价值的。

为了分析我们的模型在稀疏点云中的潜力，我们通过两种类型的点子采样来模拟点子少得多的扫描：

均匀随机子采样（以均匀分布去除现有的点）和基于ORB[40]关键点的子采样（对图像上的ORB关键点进行采样，只保留与这些2D关键点接近的3D点）。

我们展示了不同分布和密度的点云输入的检测结果。<u>我们看到，在 "点云 "一栏中，随着点数量的减少，三维检测性能迅速下降。</u>另一方面，我们看到包括图像线索在内的性能有明显的提高。当采样点来自ORB的关键点时，这种改善是最显著的，这些关键点的分布更加不均匀。

## 总结

在这项工作中，我们已经探索了<u>图像数据如何协助基于投票的三维pipeline</u>。我们建立的VOTE NET检测器依靠投票机制来有效地**汇总点云中的几何信息**。

（二维集成到三维）IMVOTENET，可以利用现有的图像检测器来提供关于物体的几何和语义/纹理信息，其格式可以集成到三维投票管道中。**具体而言，我们已经展示了如何利用相机参数和像素深度的知识，将二维几何信息提升到三维。**

IMVOTENET利用梯度混合的**多模式训练**，极大地提高了三维物体检测性能，尤其是在点云**稀疏或分布不利**的情况下。