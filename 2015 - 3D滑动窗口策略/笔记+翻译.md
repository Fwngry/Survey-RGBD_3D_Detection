（跨模态）以前的研究主要集中在只使用一种模式来检测物体，而忽略了对跨模式线索的利用。在这项工作中，我们提出了一个（基于深度玻尔兹曼机）DBM的跨模态深度学习框架，用于3D场景物体检测。特别是，我们证明了通过从RGBD数据中学习跨模态特征，有可能捕捉到它们的联合信息来加强单个模态的检测器训练。

（滑动窗口）特别是，我们在三维点云中滑动了一个三维检测窗口，以匹配典范的形状。

通过以下方式克服了三维领域训练数据的缺乏：

(1) 我们从互联网上收集三维CAD模型和二维正面样本。

(2) 采用预训练的R-CNNs[2]从RGB和Depth领域提取原始特征。

在RMRC数据集上的实验表明，基于双模的深度特征学习框架有助于3D场景物体检测。

![image-20210617110404352](https://oj84-1259326782.cos.ap-chengdu.myqcloud.com/uPic/2021/06_17_06_17_image-20210617110404352.png)

> 给定一个场景的RGBD图像，检测任务是找出现实世界中的物体实例，如椅子和桌子，它们被表示为三维立方体。
>
> 我们的框架将Kinect的RGBD图像与重力方向作为输入。大多数物体被认为是在重力方向上排列的，所以只有围绕重力轴的旋转。
>
> 为了支持三维滑动窗口，三维空间被划分为大小为0.1米的立方体单元。
>
> 为了训练双模DBM，我们利用现有的大规模语义标签数据集（如ImageNet）中标记的2D样本，并从Google Trimble 3D Warehouse中下载CAD模型来生成3D正向训练样本。
>
> 给定一个RGBD图像，我们首先根据相机参数[10]生成一个场景的点云。接下来，我们在点云中详尽地滑动一个三维边界盒，以获得所有典范-SVMs的分数。然后，三维边界框被投影到RGB通道和深度通道的二维边界框中，并以RGBD图像为参考。之后，分别通过R-CNNs和提议的双模态DBM依次提取原始特征和融合表示。然后，联合表示被用来为所有的Exemplar-SVMs获得分数。最后，对三维中的所有检测框进行非最大限度的抑制。

## 1. 引言

随着Kinect等深度传感器的普及，如今需要处理和分析的RGB-深度（RGBD）数据呈爆炸性增长，在机器人导航、无人驾驶汽车、游戏和娱乐等方面有广泛的应用。这些应用的核心是RGBD场景解析的问题，即推断单个像素的标签以解析其语义结构。

（之前的方案：超像素 - 鉴别 - 联合优化）解析的过程与二维图像中的过程相似。在一个典型的设置中，verxels首先被过度分割成superxels[1, 4, 5]。随后，个别超级像素的语义标签使用鉴别性[1，4]或生成性[6，7]方案进行推断，随后使用条件随机场（CRF）[1，4]或马尔科夫随机单元（MRF）[5，8]等模型对空间上邻近的超级像素的标签进行联合优化。

**问题：RGBD标签太少；解决思路：把二维领域的标签迁移到RGBD上**

（重要性：正负标签的充分性，决定了模版的训练）<u>基于检测的标签</u>已经吸引了越来越多的研究兴趣[6, 7]。在这种情况下，检测器的模板是由每一类标签的正负例子训练出来的。然而，检测器的准确性在很大程度上取决于训练标签的充分性[6, 7]，而这又很难保证与二维案例相比。

（很缺乏）据我们所知，现有的RGBD图像的标签大多是几百到几千个，例如，纽约大学[11]、RMRC[10]和SUN3D[12]，与ImageNet[13]、LabelMe[14]和Tiny Images[15]等图像领域的努力相比，其规模较小。一方面，在其最早的阶段，它还需要很长的时间来积累研究界的足够的标签。另一方面，与二维情况相比，为RGBD区域或立方体贴标签要困难得多，这通常需要对RGBD数据进行交互式旋转和缩放，并在图形界面上呈现。此外，在将标签转移到三维领域后，非常需要强大的检测算法来处理这种 "领域转移"。

**因此，一个自然的想法是将从二维领域获得的标签 "转移 "到RGBD的情况下，以有利于检测器的训练。**在二维领域所做的大量基准工作积累了大量关于物体的标签，其中包含丰富的二维外观，如形状、纹理和颜色等。在计算机视觉界，它导致了长达十年之久的建立大规模标签数据集的努力，这对二维图像分割、标签、分类和物体检测显示了巨大的好处。作为一种补偿，深度数据提供了有用的空间信息，这些信息有可能，但很难从单一的RGBD图像中估计出来[17]。鉴于RGBD数据的缺陷，例如传感器噪声、不同视图中的深度缺失以及遮挡和背景干扰[10]，<u>直接从RGB和深度域中分别借用标签和数据结构是不可能的。</u>

（跨模态学习）然而，我们能否从RGB数据和深度模态中学习特征表示，以促进RGBD数据的解析？这样的跨模式学习，即使不是不可能，也可以为RGBD的特征表示设计和检测器学习打开一扇大门。而这一点在以往的研究中还没有触及，也就是说，以往的工作[1, 4, 5, 8, 18]主要集中在只用一种模式来学习特征表示和检测器。

现有的一项工作来自Bo等人[7]，该工作合并了参考图像和三维点云的检测结果，以提高使用单一模式的解析精度。然而，这种结合只是简单的检测器得分与手工加权的融合，无法描述两种模态之间的复杂关联性。

**在本文中，我们通过采用跨越RGB和深度模态的特征级学习来征服这一挑战。**为此，我们提出了一个双模态深度学习框架来学习RGBD领域的鲁棒检测器，如图1中的框架所示。

1. 对于双模特征学习，我们利用深度波尔兹曼机（DBM）来学习RGB数据和深度数据的特征。
2. 为了进行稳健的检测，我们使用学到的DBM的融合表示来训练Exemplar-SVMs，它通过训练特定实例的指标和分类器，来确保灵活性和通用性。

本文的其余部分组织如下。第2节调查了相关工作。第3节介绍了拟议的方案。第4节提供了详细的双模DBM。第5节说明了模范-SVMs的训练。第6节提供了实验结果和与现有方法的比较。最后，我们在第7节中总结了本文。

## 2.相关工作

（克服训练数据有限的问题）为了克服训练数据有限的挑战，最近的一些工作[7, 10, 16]提出从相关领域进行标签转移，如LabelMe和ImageNet。

[7]和[10]中的工作利用了谷歌Trimble 3D仓库的CAD模型来渲染目标物体的3D数据作为正样本。Wang等人[16]利用现有的大规模二维语义标签数据集，如ImageNet和LabelMe，结合基于Exemplar-SVMs[23]的分类器，将标签从二维图像转移到三维点云。

**没有一个现有的作品在特征表示部分利用二维和三维之间的联合学习。**

（跨模态学习）近年来，深度学习技术已经成功地应用于学习跨模式的特征[24, 25]。

Ngiam等人[24]提出了一个基于深度学习的多模态学习方案，该方案的表现优于从单一模态学习的特征。

Srivastava和Salkhutdinov[25]提出了一个DBM模型，用于学习由多种不同输入模态组成的数据生成模型。该模型通过学习可见单元空间的概率来工作，其中潜在变量的状态被用作多模态输入的联合表示。

**与我们的工作最相似的作品是[7]和[10]。然而，也有一些根本性的区别。**

首先，在这项工作中，我们从互联网上收集二维和计算机图形（CG）CAD模型的训练数据。

第二，我们专注于两种不同的模式，RGB和深度。

第三，为了应对训练数据不足的挑战，我们使用了预训练的R-CNNs来提取RGB和Depth通道的原始特征。
